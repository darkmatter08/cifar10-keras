{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.2.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow; tensorflow.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import cifar10\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "NCLASSES = 10\n",
    "y_train = keras.utils.to_categorical(y_train, NCLASSES)\n",
    "y_test = keras.utils.to_categorical(y_test, NCLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Using more advanced data augmentation prevents the model from generalizing.\n",
    "## val_acc gets stuck around 10%, even though acc reaches 40%\n",
    "# train_datagen = ImageDataGenerator(\n",
    "# featurewise_center=True,\n",
    "# samplewise_center=True,\n",
    "# featurewise_std_normalization=True,\n",
    "# rotation_range=10,\n",
    "# zoom_range = 0.9,\n",
    "# horizontal_flip=True\n",
    "# )\n",
    "\n",
    "train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images\n",
    "\n",
    "train_datagen.fit(x_train)\n",
    "train_generator = train_datagen.flow(x_train, y_train)\n",
    "train_generator.samples = x_train.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_datagen=ImageDataGenerator()\n",
    "val_generator = val_datagen.flow(x_test, y_test)\n",
    "val_generator.samples = x_test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def makemodel():\n",
    "    from keras.models import Sequential\n",
    "    from keras.layers import Dense, Dropout, Flatten\n",
    "    from keras.layers import Conv2D, MaxPooling2D\n",
    "    model = Sequential()\n",
    "    # input: 32, 32 images with 3 channels -> (32,32, 3) tensors.\n",
    "    # this applies 32 convolution filters of size 3x3 each.\n",
    "    model.add(Conv2D(256, (6, 6), activation='relu', input_shape=(32, 32, 3)))\n",
    "    model.add(Conv2D(128, (6, 6), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(Dropout(0.25))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(NCLASSES, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 27, 27, 256)       27904     \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 22, 22, 128)       1179776   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,160,138\n",
      "Trainable params: 2,160,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model('cifar10-cb.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_57 (Conv2D)           (None, 27, 27, 256)       27904     \n",
      "_________________________________________________________________\n",
      "conv2d_58 (Conv2D)           (None, 22, 22, 128)       1179776   \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "dropout_34 (Dropout)         (None, 11, 11, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_59 (Conv2D)           (None, 9, 9, 128)         147584    \n",
      "_________________________________________________________________\n",
      "conv2d_60 (Conv2D)           (None, 7, 7, 128)         147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_35 (Dropout)         (None, 3, 3, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_13 (Flatten)         (None, 1152)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 512)               590336    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 128)               65664     \n",
      "_________________________________________________________________\n",
      "dropout_36 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                1290      \n",
      "=================================================================\n",
      "Total params: 2,160,138\n",
      "Trainable params: 2,160,138\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# from keras.applications.resnet50 import ResNet50\n",
    "# model = ResNet50(weights=None, classes=10)\n",
    "model = makemodel()\n",
    "model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.rmsprop(lr=0.0001, decay=1e-6), metrics=['accuracy'])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/200\n",
      " 329/1562 [=====>........................] - ETA: 61s - loss: 1.8006 - acc: 0.4046"
     ]
    }
   ],
   "source": [
    "saver_cb = keras.callbacks.ModelCheckpoint(\n",
    "    'cifar10-cb.h5',\n",
    "    monitor='val_acc',\n",
    "    verbose=1,\n",
    "    save_best_only=True\n",
    ")\n",
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=int(train_generator.samples/train_generator.batch_size),\n",
    "    epochs=200,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=int(val_generator.samples/val_generator.batch_size),\n",
    "    initial_epoch=20,\n",
    "    callbacks=[saver_cb]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: reach about 0.70 val_acc.\n",
    "# Observations\n",
    "I noticed some divergence between acc and val_acc. For example, in Epoch 23, acc was 0.40 but val_acc was .50. If there is less correlation, then training for more epochs won't necessarily help!\n",
    "Accuracy collaposed after Epoch 25 back to 0.1 (guessing). Need to add in variable LR."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
